{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "90qDRfe4pWc5",
        "outputId": "5df79d41-9359-46e7-cc14-8482667cfb7c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# deletion\n",
        "def indicineprotvar(hfprotvar_wd, chr, outloc):\n",
        "  print(\"hffinal_df\", hfprotvar_wd.shape)\n",
        "  in_f1=f\"/content/drive/MyDrive/gene_ext/ind_protein/ind_chr{chr}_prot.csv\"\n",
        "  ind_prot=pd.read_csv(in_f1)\n",
        "  ind_prot[\"indstart_of_next_gene\"] = ind_prot[\"Start\"].shift(-1).fillna(0)\n",
        "  finalindprot_df=pd.DataFrame(columns=list(hfprotvar_wd)+[\"NelStart\"]+[\"NelStop\"]+[\"NelLocus\"]+[\"NelLength\"]+[\"NelProt\"]+[\"Nelnextgen\"]+[\"Nelgene_type\"])\n",
        "  for i, row in tqdm(ind_prot.iterrows()):\n",
        "    # Check for the at start\n",
        "    if hfprotvar_wd[(row[\"Start\"]==hfprotvar_wd[\"startpos.q\"]) & (row[\"Stop\"]>hfprotvar_wd[\"endpos.q\"])].shape[0]>=1:\n",
        "        tmp_df = hfprotvar_wd[(row[\"Start\"]==hfprotvar_wd[\"startpos.q\"]) & (row[\"Stop\"]>hfprotvar_wd[\"endpos.q\"])].copy(deep=True)\n",
        "        tmp_df[\"Nelgene_type\"] = \"at_start\"\n",
        "        tmp_df[\"NelStart\"] = row[\"Start\"]\n",
        "        tmp_df[\"NelStop\"] = row[\"Stop\"]\n",
        "        tmp_df[\"NelLocus\"] = row[\"Locus\"]\n",
        "        tmp_df[\"NelLength\"] = row[\"Length\"]\n",
        "        tmp_df[\"NelProt\"] = row[\"Protein Name\"]\n",
        "        tmp_df[\"Nelnextgen\"] = row[\"indstart_of_next_gene\"]\n",
        "        finalindprot_df = pd.concat([finalindprot_df,tmp_df]).reset_index(drop=True)\n",
        "    # check for the at end\n",
        "    elif hfprotvar_wd[(row[\"Start\"]<hfprotvar_wd[\"startpos.q\"]) & (row[\"Stop\"]==hfprotvar_wd[\"endpos.q\"])].shape[0]>=1:\n",
        "        tmp_df = hfprotvar_wd[(row[\"Start\"]<hfprotvar_wd[\"startpos.q\"]) & (row[\"Stop\"]==hfprotvar_wd[\"endpos.q\"])].copy(deep=True)\n",
        "        tmp_df[\"Nelgene_type\"] = \"at_end\"\n",
        "        tmp_df[\"NelStart\"] = row[\"Start\"]\n",
        "        tmp_df[\"NelStop\"] = row[\"Stop\"]\n",
        "        tmp_df[\"NelLocus\"] = row[\"Locus\"]\n",
        "        tmp_df[\"NelLength\"] = row[\"Length\"]\n",
        "        tmp_df[\"NelProt\"] = row[\"Protein Name\"]\n",
        "        tmp_df[\"Nelnextgen\"] = row[\"indstart_of_next_gene\"]\n",
        "        finalindprot_df = pd.concat([finalindprot_df,tmp_df]).reset_index(drop=True)\n",
        "    # Check for the within gene\n",
        "    elif hfprotvar_wd[(row[\"Start\"]<hfprotvar_wd[\"startpos.q\"]) & (row[\"Stop\"]>hfprotvar_wd[\"endpos.q\"])].shape[0]>=1:\n",
        "        tmp_df = hfprotvar_wd[(row[\"Start\"]<hfprotvar_wd[\"startpos.q\"]) & (row[\"Stop\"]>hfprotvar_wd[\"endpos.q\"])].copy(deep=True)\n",
        "        tmp_df[\"Nelgene_type\"] = \"within_gene\"\n",
        "        tmp_df[\"NelStart\"] = row[\"Start\"]\n",
        "        tmp_df[\"NelStop\"] = row[\"Stop\"]\n",
        "        tmp_df[\"NelLocus\"] = row[\"Locus\"]\n",
        "        tmp_df[\"NelLength\"] = row[\"Length\"]\n",
        "        tmp_df[\"NelProt\"] = row[\"Protein Name\"]\n",
        "        tmp_df[\"Nelnextgen\"] = row[\"indstart_of_next_gene\"]\n",
        "        finalindprot_df = pd.concat([finalindprot_df,tmp_df]).reset_index(drop=True)\n",
        "    # Check for the intergenic gene\n",
        "    elif hfprotvar_wd[(row[\"Stop\"]<hfprotvar_wd[\"startpos.q\"]) & (row[\"indstart_of_next_gene\"]>hfprotvar_wd[\"endpos.q\"])].shape[0]>=1:\n",
        "        tmp_df = hfprotvar_wd[(row[\"Stop\"]<hfprotvar_wd[\"startpos.q\"]) & (row[\"indstart_of_next_gene\"]>hfprotvar_wd[\"endpos.q\"])].copy(deep=True)\n",
        "        tmp_df[\"Nelgene_type\"] = \"intergenic_gene\"\n",
        "        tmp_df[\"NelStart\"] = row[\"Start\"]\n",
        "        tmp_df[\"NelStop\"] = row[\"Stop\"]\n",
        "        tmp_df[\"NelLocus\"] = row[\"Locus\"]\n",
        "        tmp_df[\"NelLength\"] = row[\"Length\"]\n",
        "        tmp_df[\"NelProt\"] = row[\"Protein Name\"]\n",
        "        tmp_df[\"Nelnextgen\"] = row[\"indstart_of_next_gene\"]\n",
        "        finalindprot_df = pd.concat([finalindprot_df,tmp_df]).reset_index(drop=True)\n",
        "    else:\n",
        "        pass\n",
        "\n",
        "\n",
        "  # Generate output file\n",
        "  out_file16=f\"hfqtl_NelVar{chr}.csv\"\n",
        "  finalindprot_df.to_csv(out_file16)\n",
        "  shutil.copy(out_file16, outloc)\n",
        "\n",
        "  # # extract only the immune genes\n",
        "  # hfimm_nel = pd.DataFrame\n",
        "  # hfimm_nel=finalindprot_df[finalindprot_df[\"keyword_found\"]==True]\n",
        "  # out_file17=f\"hfimm_nel{chr}.csv\"\n",
        "  # hfimm_nel.to_csv(out_file17)\n",
        "  # shutil.copy(out_file17, outloc)\n",
        "\n",
        "  # LOV50\n",
        "  hfNel_LOV50=finalindprot_df[finalindprot_df[\"LOV\"]>=50]\n",
        "  # hfNelimm_LOV50=hfimm_nel[hfimm_nel[\"LOV\"]>=50]\n",
        "  out_file18=f\"hfNel_LOV50_{chr}.csv\"\n",
        "  # out_file19=f\"hfNelimm_LOV50_{chr}.csv\"\n",
        "  hfNel_LOV50.to_csv(out_file18)\n",
        "  # hfNelimm_LOV50.to_csv(out_file19)\n",
        "  shutil.copy(out_file18, outloc)\n",
        "  # shutil.copy(out_file19, outloc)\n"
      ],
      "metadata": {
        "id": "GVFTvduBCx2Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def hfqtl_VarAnal(common_df, hfqtl_df, chr, outloc):\n",
        "  # Identifying the variations\n",
        "  final_df = pd.DataFrame(columns=list(hfqtl_df.columns)+[\"HFgene_type\"]+[\"startpos.r\"]+[\"endpos.r\"]+[\"startpos.q\"]+[\"endpos.q\"]+[\"seq.r\"]+[\"seq.q\"]+[\"LOV\"])\n",
        "  for i, row in tqdm(common_df.iterrows()):\n",
        "    # Check for the at start\n",
        "    if hfqtl_df[(hfqtl_df[\"Begin\"]==row[\"startpos.r\"]) & (hfqtl_df[\"End\"]>row[\"endpos.r\"])].shape[0]>=1:\n",
        "        tmp_df = hfqtl_df[(hfqtl_df[\"Begin\"]==row[\"startpos.r\"]) & (hfqtl_df[\"End\"]>row[\"endpos.r\"])].copy(deep=True)\n",
        "        tmp_df[\"HFgene_type\"] = \"at_start\"\n",
        "        tmp_df[\"startpos.r\"] = row[\"startpos.r\"]\n",
        "        tmp_df[\"endpos.r\"] = row[\"endpos.r\"]\n",
        "        tmp_df[\"startpos.q\"] = row[\"startpos.q\"]\n",
        "        tmp_df[\"endpos.q\"] = row[\"endpos.q\"]\n",
        "        tmp_df[\"seq.r\"] = row[\"seq.r\"]\n",
        "        tmp_df[\"seq.q\"] = row[\"seq.q\"]\n",
        "        tmp_df[\"LOV\"] = row[\"LOV\"]\n",
        "        final_df = pd.concat([final_df,tmp_df]).reset_index(drop=True)\n",
        "    # check for the at end\n",
        "    elif hfqtl_df[(hfqtl_df[\"Begin\"]<row[\"startpos.r\"]) & (hfqtl_df[\"End\"]==row[\"endpos.r\"])].shape[0]>=1:\n",
        "        tmp_df = hfqtl_df[(hfqtl_df[\"Begin\"]<row[\"startpos.r\"]) & (hfqtl_df[\"End\"]==row[\"endpos.r\"])].copy(deep=True)\n",
        "        tmp_df[\"HFgene_type\"] = \"at_end\"\n",
        "        tmp_df[\"startpos.r\"] = row[\"startpos.r\"]\n",
        "        tmp_df[\"endpos.r\"] = row[\"endpos.r\"]\n",
        "        tmp_df[\"startpos.q\"] = row[\"startpos.q\"]\n",
        "        tmp_df[\"endpos.q\"] = row[\"endpos.q\"]\n",
        "        tmp_df[\"seq.r\"] = row[\"seq.r\"]\n",
        "        tmp_df[\"seq.q\"] = row[\"seq.q\"]\n",
        "        tmp_df[\"LOV\"] = row[\"LOV\"]\n",
        "        final_df = pd.concat([final_df,tmp_df]).reset_index(drop=True)\n",
        "    # Check for the within gene\n",
        "    elif hfqtl_df[(hfqtl_df[\"Begin\"]<row[\"startpos.r\"]) & (hfqtl_df[\"End\"]>row[\"endpos.r\"])].shape[0]>=1:\n",
        "        tmp_df = hfqtl_df[(hfqtl_df[\"Begin\"]<row[\"startpos.r\"]) & (hfqtl_df[\"End\"]>row[\"endpos.r\"])].copy(deep=True)\n",
        "        tmp_df[\"HFgene_type\"] = \"within_gene\"\n",
        "        tmp_df[\"startpos.r\"] = row[\"startpos.r\"]\n",
        "        tmp_df[\"endpos.r\"] = row[\"endpos.r\"]\n",
        "        tmp_df[\"startpos.q\"] = row[\"startpos.q\"]\n",
        "        tmp_df[\"endpos.q\"] = row[\"endpos.q\"]\n",
        "        tmp_df[\"seq.r\"] = row[\"seq.r\"]\n",
        "        tmp_df[\"seq.q\"] = row[\"seq.q\"]\n",
        "        tmp_df[\"LOV\"] = row[\"LOV\"]\n",
        "        final_df = pd.concat([final_df,tmp_df]).reset_index(drop=True)\n",
        "    # Check for the intergenic gene\n",
        "    elif hfqtl_df[(hfqtl_df[\"End\"]<row[\"startpos.r\"]) & (hfqtl_df[\"hfstart_of_next_gene\"]>row[\"endpos.r\"])].shape[0]>=1:\n",
        "        tmp_df = hfqtl_df[(hfqtl_df[\"End\"]<row[\"startpos.r\"]) & (hfqtl_df[\"hfstart_of_next_gene\"]>row[\"endpos.r\"])].copy(deep=True)\n",
        "        tmp_df[\"HFgene_type\"] = \"intergenic_gene\"\n",
        "        tmp_df[\"startpos.r\"] = row[\"startpos.r\"]\n",
        "        tmp_df[\"endpos.r\"] = row[\"endpos.r\"]\n",
        "        tmp_df[\"startpos.q\"] = row[\"startpos.q\"]\n",
        "        tmp_df[\"endpos.q\"] = row[\"endpos.q\"]\n",
        "        tmp_df[\"seq.r\"] = row[\"seq.r\"]\n",
        "        tmp_df[\"seq.q\"] = row[\"seq.q\"]\n",
        "        tmp_df[\"LOV\"] = row[\"LOV\"]\n",
        "        final_df = pd.concat([final_df,tmp_df]).reset_index(drop=True)\n",
        "    # Check for the at start with intergenic gene\n",
        "    elif hfqtl_df[(hfqtl_df[\"Begin\"]>row[\"startpos.r\"]) & (hfqtl_df[\"Begin\"]==row[\"endpos.r\"])].shape[0]>=1:\n",
        "        tmp_df = hfqtl_df[(hfqtl_df[\"Begin\"]>row[\"startpos.r\"]) & (hfqtl_df[\"Begin\"]==row[\"endpos.r\"])].copy(deep=True)\n",
        "        tmp_df[\"HFgene_type\"] = \"intergenic_gene\"\n",
        "        tmp_df[\"startpos.r\"] = row[\"startpos.r\"]\n",
        "        tmp_df[\"endpos.r\"] = row[\"endpos.r\"]\n",
        "        tmp_df[\"startpos.q\"] = row[\"startpos.q\"]\n",
        "        tmp_df[\"endpos.q\"] = row[\"endpos.q\"]\n",
        "        tmp_df[\"seq.r\"] = row[\"seq.r\"]\n",
        "        tmp_df[\"seq.q\"] = row[\"seq.q\"]\n",
        "        tmp_df[\"LOV\"] = row[\"LOV\"]\n",
        "        final_df = pd.concat([final_df,tmp_df]).reset_index(drop=True)\n",
        "    # Check for the at end with intergenic gene\n",
        "    elif hfqtl_df[(hfqtl_df[\"End\"]==row[\"startpos.r\"]) & (hfqtl_df[\"End\"]<row[\"endpos.r\"])].shape[0]>=1:\n",
        "        tmp_df = hfqtl_df[(hfqtl_df[\"End\"]==row[\"startpos.r\"]) & (hfqtl_df[\"End\"]<row[\"endpos.r\"])].copy(deep=True)\n",
        "        tmp_df[\"HFgene_type\"] = \"intergenic_gene\"\n",
        "        tmp_df[\"startpos.r\"] = row[\"startpos.r\"]\n",
        "        tmp_df[\"endpos.r\"] = row[\"endpos.r\"]\n",
        "        tmp_df[\"startpos.q\"] = row[\"startpos.q\"]\n",
        "        tmp_df[\"endpos.q\"] = row[\"endpos.q\"]\n",
        "        tmp_df[\"seq.r\"] = row[\"seq.r\"]\n",
        "        tmp_df[\"seq.q\"] = row[\"seq.q\"]\n",
        "        tmp_df[\"LOV\"] = row[\"LOV\"]\n",
        "        final_df = pd.concat([final_df,tmp_df]).reset_index(drop=True)\n",
        "    # Check for the near start with intergenic gene\n",
        "    elif hfqtl_df[(hfqtl_df[\"Begin\"]>row[\"startpos.r\"]) & (hfqtl_df[\"Begin\"]<row[\"endpos.r\"])].shape[0]>=1:\n",
        "        tmp_df = hfqtl_df[(hfqtl_df[\"Begin\"]>row[\"startpos.r\"]) & (hfqtl_df[\"Begin\"]<row[\"endpos.r\"])].copy(deep=True)\n",
        "        tmp_df[\"HFgene_type\"] = \"intergenic_gene\"\n",
        "        tmp_df[\"startpos.r\"] = row[\"startpos.r\"]\n",
        "        tmp_df[\"endpos.r\"] = row[\"endpos.r\"]\n",
        "        tmp_df[\"startpos.q\"] = row[\"startpos.q\"]\n",
        "        tmp_df[\"endpos.q\"] = row[\"endpos.q\"]\n",
        "        tmp_df[\"seq.r\"] = row[\"seq.r\"]\n",
        "        tmp_df[\"seq.q\"] = row[\"seq.q\"]\n",
        "        tmp_df[\"LOV\"] = row[\"LOV\"]\n",
        "        final_df = pd.concat([final_df,tmp_df]).reset_index(drop=True)\n",
        "    # Check for the near end with intergenic gene\n",
        "    elif hfqtl_df[(hfqtl_df[\"End\"]>row[\"startpos.r\"]) & (hfqtl_df[\"End\"]<row[\"endpos.r\"])].shape[0]>=1:\n",
        "        tmp_df = hfqtl_df[(hfqtl_df[\"End\"]>row[\"startpos.r\"]) & (hfqtl_df[\"End\"]<row[\"endpos.r\"])].copy(deep=True)\n",
        "        tmp_df[\"HFgene_type\"] = \"intergenic_gene\"\n",
        "        tmp_df[\"startpos.r\"] = row[\"startpos.r\"]\n",
        "        tmp_df[\"endpos.r\"] = row[\"endpos.r\"]\n",
        "        tmp_df[\"startpos.q\"] = row[\"startpos.q\"]\n",
        "        tmp_df[\"endpos.q\"] = row[\"endpos.q\"]\n",
        "        tmp_df[\"seq.r\"] = row[\"seq.r\"]\n",
        "        tmp_df[\"seq.q\"] = row[\"seq.q\"]\n",
        "        tmp_df[\"LOV\"] = row[\"LOV\"]\n",
        "        final_df = pd.concat([final_df,tmp_df]).reset_index(drop=True)\n",
        "    else:\n",
        "        pass\n",
        "\n",
        "  # Generate output file\n",
        "  out_file3=f\"hfprotvar{chr}.csv\"\n",
        "  final_df.to_csv(out_file3)\n",
        "  shutil.copy(out_file3, outloc)\n",
        "\n",
        "  # find variation not present in gene and intergene region called as other non coding region\n",
        "  final_df1 = pd.DataFrame(columns=common_df.columns)\n",
        "  for index, row in tqdm(common_df.iterrows()):\n",
        "    # Check if 'startpos.q' is present in any row of file2\n",
        "    if row['startpos.q'] not in final_df['startpos.q'].values:\n",
        "        # Append the row to the DataFrame if not found\n",
        "        final_df1 = final_df1.append(row, ignore_index=True)\n",
        "\n",
        "  # Save the DataFrame with rows not found in file2 to a new CSV file\n",
        "  out_file4=f\"non_coding{chr}.csv\"\n",
        "  final_df1.to_csv(out_file4, index=False)\n",
        "  shutil.copy(out_file4, outloc)\n",
        "\n",
        "  # remove duplicates\n",
        "  hfprotvar_wd = final_df.drop_duplicates(subset=['Symbol', \"QTL Class\", 'startpos.r', 'endpos.r'])\n",
        "  out_file5=f\"hfprotvar_wd{chr}.csv\"\n",
        "  hfprotvar_wd.to_csv(out_file5)\n",
        "  shutil.copy(out_file5, outloc)\n",
        "\n",
        "  # extract only the immune genes\n",
        "  hfimm = pd.DataFrame\n",
        "  hfimm=hfprotvar_wd[hfprotvar_wd[\"keyword_found\"]==True]\n",
        "  out_file6=f\"hfimm{chr}.csv\"\n",
        "  hfimm.to_csv(out_file6)\n",
        "  shutil.copy(out_file6, outloc)\n",
        "\n",
        "  # Extract the variation presents in gene and intergene seperately\n",
        "  hf_within_gene=hfprotvar_wd[hfprotvar_wd[\"HFgene_type\"]==\"within_gene\"]\n",
        "  hf_inter_gene=hfprotvar_wd[hfprotvar_wd[\"HFgene_type\"]==\"intergenic_gene\"]\n",
        "\n",
        "  # extract the variations among genomic regions including gene and intergene has greater the 50 LOV (length of varaition)\n",
        "  hf_LOV50=hfprotvar_wd[hfprotvar_wd[\"LOV\"]>=50]\n",
        "\n",
        "  out_file7=f\"hf_within_gene{chr}.csv\"\n",
        "  out_file8=f\"hf_inter_gene{chr}.csv\"\n",
        "  out_file9=f\"hf_LOV50_{chr}.csv\"\n",
        "\n",
        "  hf_within_gene.to_csv(out_file7)\n",
        "  hf_inter_gene.to_csv(out_file8)\n",
        "  hf_LOV50.to_csv(out_file9)\n",
        "\n",
        "  shutil.copy(out_file7, outloc)\n",
        "  shutil.copy(out_file8, outloc)\n",
        "  shutil.copy(out_file9, outloc)\n",
        "\n",
        "  # Extract the variation presents in immune gene and intergene seperately\n",
        "  hfimm_within_gene=hfimm[hfimm[\"HFgene_type\"]==\"within_gene\"]\n",
        "  hfimm_inter_gene=hfimm[hfimm[\"HFgene_type\"]==\"intergenic_gene\"]\n",
        "\n",
        "  # extract the variations among genomic regions including gene and intergene has greater the 50 LOV (length of varaition)\n",
        "  hfimm_LOV50=hfimm[hfimm[\"LOV\"]>=50]\n",
        "\n",
        "  out_file10=f\"hfimm_within_gene{chr}.csv\"\n",
        "  out_file11=f\"hfimm_inter_gene{chr}.csv\"\n",
        "  out_file12=f\"hfimm_LOV50_{chr}.csv\"\n",
        "\n",
        "  hfimm_within_gene.to_csv(out_file10)\n",
        "  hfimm_inter_gene.to_csv(out_file11)\n",
        "  hfimm_LOV50.to_csv(out_file12)\n",
        "\n",
        "  shutil.copy(out_file10, outloc)\n",
        "  shutil.copy(out_file11, outloc)\n",
        "  shutil.copy(out_file12, outloc)\n",
        "\n",
        "  # count the variation based on gene type\n",
        "  hfvar_counts = hfprotvar_wd.drop_duplicates(subset=['Symbol', 'startpos.r', 'endpos.r'])\n",
        "  gene_count=hfvar_counts.groupby([\"HFgene_type\"]).size().reset_index(name=\"count\")\n",
        "  out_file13=f\"var_count{chr}.csv\"\n",
        "  gene_count.to_csv(out_file13)\n",
        "  shutil.copy(out_file13, outloc)\n",
        "\n",
        "  # extract the immune has how many variations and its gene type\n",
        "  hfimmvar_counts = hfimm.drop_duplicates(subset=['Symbol', 'startpos.r', 'endpos.r'])\n",
        "  imm_count=hfimmvar_counts.groupby(by=[\"Symbol\",\"Name\", \"HFgene_type\"]).size().reset_index(name=\"count\")\n",
        "  out_file14=f\"immlocus_gene_type_counts{chr}.csv\"\n",
        "  imm_count.to_csv(out_file14, index=False)\n",
        "  shutil.copy(out_file14, outloc)\n",
        "\n",
        "  # Calculate value counts\n",
        "  count = hfprotvar_wd[\"HFgene_type\"].value_counts().reset_index()\n",
        "  count.columns = [\"HFgene_type\", \"Count\"]\n",
        "  count.loc[len(count.index)]=[\"immune_gene\", len(hfimm_within_gene)]\n",
        "  count.loc[len(count.index)]=[\"non_coding_gene\", len(final_df1)]\n",
        "\n",
        "\n",
        "  # Save the result to a CSV file\n",
        "  out_file15=f\"delcount{chr}.csv\"\n",
        "  count.to_csv(out_file15, index=False)\n",
        "  shutil.copy(out_file15, outloc)\n",
        "\n",
        "  #extract idicine genes\n",
        "  indicineprotvar(hfprotvar_wd, chr, outloc)"
      ],
      "metadata": {
        "id": "lRjg43mLDjdo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def map_keywords(str_sentence):\n",
        "    list_keywords = [\n",
        "        \"immunoglobulin\",\"immunoreceptor\",\"autoimmune\",\"TLR\",\"IgG\",\n",
        "        \"autoimmune\",\"autophagy\",\"immunogen\",\"immune\",\"innate\",\"T-cell\",\"NF-kappa\", \"antigen\",\n",
        "        \"B-cell\",\"lymphocyte\",\"histocompatibility\",\"CD24\",\"CD4\",\"LY96\", \"BCR\",\n",
        "        \"IFIT3\",\"PGLYRP1\",\"NKG2D\",\"UL16\",\"leukocyte\",\"cytokine\", \"interleukin\",\"interferon\"\n",
        "        \"antimicrobial peptide\",\"beta-defensin 2\",\"IL16\",\"IL2\",\"chemokine\", \"antibody\"\n",
        "    ]\n",
        "    bool_found = bool(\n",
        "        [\n",
        "            i for i in list_keywords if i.lower() in str_sentence.lower()\n",
        "        ]\n",
        "    )\n",
        "    return bool_found\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "import shutil\n",
        "\n",
        "Chr_list=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, \"X\"]\n",
        "# Chr_list=[\"X\"]\n",
        "for chr in Chr_list:\n",
        "  in_file1=f\"/content/drive/MyDrive/gene_ext/del/{chr}/common_wd{chr}.csv\"\n",
        "  in_file2=f\"/content/drive/MyDrive/Hereford_VarAnalysis/Hereford_qtl/{chr}/HF_QTL{chr}.csv\"\n",
        "  outloc=f\"/content/drive/MyDrive/Hereford_VarAnalysis/Hereford_chrVar/del/{chr}\"\n",
        "  common_df=pd.read_csv(in_file1)\n",
        "  hfqtl_df=pd.read_csv(in_file2)\n",
        "\n",
        "  print(\"common_df\", common_df.shape)\n",
        "  print(\"hfqtl_df\", hfqtl_df.shape)\n",
        "\n",
        "\n",
        "  common_df[\"LOV\"]=abs(common_df[\"endpos.r\"]-common_df[\"startpos.r\"])\n",
        "  out_f1=f\"common{chr}_LOV.csv\"\n",
        "\n",
        "  common_df.to_csv(out_f1)\n",
        "  shutil.copy(out_f1, outloc)\n",
        "\n",
        "  hfqtl_df[\"keyword_found\"] = hfqtl_df.apply(lambda row: map_keywords(row[\"Name\"]),axis=1)\n",
        "  out_f2=f\"hfqtlprot{chr}.csv\"\n",
        "\n",
        "  hfqtl_df.to_csv(out_f2)\n",
        "  shutil.copy(out_f2, outloc)\n",
        "\n",
        "  hfqtl_VarAnal(common_df, hfqtl_df, chr, outloc)"
      ],
      "metadata": {
        "id": "_g_rHM_-GFMx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6dd0886a-aa4e-46a2-af1b-87672417da8c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "common_df (1374, 13)\n",
            "hfqtl_df (3435, 19)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "1374it [00:11, 118.33it/s]\n",
            "1374it [00:00, 4813.43it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hffinal_df (3889, 28)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "1433it [00:06, 212.43it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "common_df (1041, 13)\n",
            "hfqtl_df (3898, 19)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "1041it [00:08, 128.12it/s]\n",
            "0it [00:00, ?it/s]<ipython-input-4-1867921baf1e>:115: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  final_df1 = final_df1.append(row, ignore_index=True)\n",
            "1041it [00:00, 5817.74it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hffinal_df (2532, 28)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "1627it [00:05, 281.54it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "common_df (1040, 13)\n",
            "hfqtl_df (4299, 19)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "1040it [00:07, 133.18it/s]\n",
            "0it [00:00, ?it/s]<ipython-input-4-1867921baf1e>:115: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  final_df1 = final_df1.append(row, ignore_index=True)\n",
            "1040it [00:00, 6494.53it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hffinal_df (2205, 28)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2269it [00:08, 280.03it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "common_df (1232, 13)\n",
            "hfqtl_df (2219, 19)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "1232it [00:08, 137.27it/s]\n",
            "1232it [00:00, 7080.01it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hffinal_df (2775, 28)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "1148it [00:04, 242.85it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "common_df (755, 13)\n",
            "hfqtl_df (7514, 19)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "755it [00:05, 133.16it/s]\n",
            "0it [00:00, ?it/s]<ipython-input-4-1867921baf1e>:115: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  final_df1 = final_df1.append(row, ignore_index=True)\n",
            "755it [00:00, 5500.64it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hffinal_df (1739, 28)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2001it [00:06, 326.22it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "common_df (1012, 13)\n",
            "hfqtl_df (12249, 19)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "1012it [00:18, 53.43it/s]\n",
            "1012it [00:00, 2010.79it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hffinal_df (3361, 28)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "1144it [00:05, 208.07it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "common_df (896, 13)\n",
            "hfqtl_df (3762, 19)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "896it [00:06, 149.12it/s]\n",
            "896it [00:00, 6013.17it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hffinal_df (2123, 28)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022it [00:06, 311.08it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "common_df (997, 13)\n",
            "hfqtl_df (2233, 19)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "997it [00:07, 138.73it/s]\n",
            "997it [00:00, 6794.96it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hffinal_df (2378, 28)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "1255it [00:05, 237.13it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "common_df (785, 13)\n",
            "hfqtl_df (1960, 19)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "785it [00:06, 126.21it/s]\n",
            "785it [00:00, 9096.97it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hffinal_df (2004, 28)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "778it [00:02, 262.88it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "common_df (851, 13)\n",
            "hfqtl_df (3005, 19)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "851it [00:06, 136.09it/s]\n",
            "851it [00:00, 6677.39it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hffinal_df (2180, 28)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "1553it [00:05, 265.26it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "common_df (748, 13)\n",
            "hfqtl_df (4621, 19)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "748it [00:05, 131.27it/s]\n",
            "748it [00:00, 4215.37it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hffinal_df (1994, 28)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "1587it [00:05, 305.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "common_df (637, 13)\n",
            "hfqtl_df (1651, 19)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "637it [00:04, 143.23it/s]\n",
            "637it [00:00, 9796.61it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hffinal_df (1568, 28)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "623it [00:02, 307.42it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "common_df (754, 13)\n",
            "hfqtl_df (2911, 19)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "754it [00:05, 139.49it/s]\n",
            "754it [00:00, 7726.73it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hffinal_df (1764, 28)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "1315it [00:04, 268.42it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "common_df (630, 13)\n",
            "hfqtl_df (8490, 19)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "630it [00:08, 75.53it/s]\n",
            "630it [00:00, 3151.87it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hffinal_df (1893, 28)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "681it [00:02, 296.81it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "common_df (913, 13)\n",
            "hfqtl_df (3026, 19)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "913it [00:06, 141.82it/s]\n",
            "913it [00:00, 8855.62it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hffinal_df (1904, 28)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "1533it [00:05, 264.91it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "common_df (649, 13)\n",
            "hfqtl_df (2580, 19)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "649it [00:04, 146.69it/s]\n",
            "649it [00:00, 5905.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hffinal_df (1600, 28)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "976it [00:03, 298.14it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "common_df (647, 13)\n",
            "hfqtl_df (4396, 19)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "647it [00:05, 125.96it/s]\n",
            "647it [00:00, 7502.73it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hffinal_df (1818, 28)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "994it [00:03, 317.52it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "common_df (731, 13)\n",
            "hfqtl_df (3023, 19)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "731it [00:04, 155.74it/s]\n",
            "731it [00:00, 8259.40it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hffinal_df (1204, 28)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "1973it [00:05, 329.38it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "common_df (567, 13)\n",
            "hfqtl_df (3535, 19)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "567it [00:03, 154.81it/s]\n",
            "0it [00:00, ?it/s]<ipython-input-4-1867921baf1e>:115: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  final_df1 = final_df1.append(row, ignore_index=True)\n",
            "567it [00:00, 7594.81it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hffinal_df (1094, 28)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2072it [00:05, 378.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "common_df (735, 13)\n",
            "hfqtl_df (4198, 19)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "735it [00:07, 97.35it/s]\n",
            "735it [00:00, 4531.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hffinal_df (2524, 28)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "480it [00:02, 202.13it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "common_df (555, 13)\n",
            "hfqtl_df (3498, 19)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "555it [00:04, 137.89it/s]\n",
            "555it [00:00, 6876.88it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hffinal_df (1328, 28)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "837it [00:04, 192.28it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "common_df (547, 13)\n",
            "hfqtl_df (1637, 19)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "547it [00:03, 145.03it/s]\n",
            "547it [00:00, 10406.00it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hffinal_df (1433, 28)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "1016it [00:03, 287.77it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "common_df (368, 13)\n",
            "hfqtl_df (2540, 19)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "368it [00:02, 155.17it/s]\n",
            "368it [00:00, 7053.12it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hffinal_df (852, 28)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "1147it [00:02, 401.32it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "common_df (417, 13)\n",
            "hfqtl_df (1149, 19)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "417it [00:02, 151.69it/s]\n",
            "417it [00:00, 8176.26it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hffinal_df (859, 28)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "561it [00:01, 323.95it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "common_df (363, 13)\n",
            "hfqtl_df (3391, 19)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "363it [00:02, 136.76it/s]\n",
            "363it [00:00, 7070.79it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hffinal_df (904, 28)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "1240it [00:03, 384.58it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "common_df (530, 13)\n",
            "hfqtl_df (5274, 19)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "530it [00:06, 76.95it/s]\n",
            "530it [00:00, 2872.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hffinal_df (1855, 28)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "718it [00:03, 236.86it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "common_df (382, 13)\n",
            "hfqtl_df (1515, 19)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "382it [00:02, 135.58it/s]\n",
            "382it [00:00, 11232.09it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hffinal_df (1000, 28)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "356it [00:01, 303.76it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "common_df (397, 13)\n",
            "hfqtl_df (1023, 19)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "397it [00:03, 128.29it/s]\n",
            "397it [00:00, 8045.70it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hffinal_df (1098, 28)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "578it [00:01, 327.68it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "common_df (656, 13)\n",
            "hfqtl_df (3908, 19)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "656it [00:06, 97.55it/s]\n",
            "656it [00:00, 4687.66it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hffinal_df (1998, 28)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "970it [00:03, 264.34it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "common_df (1913, 13)\n",
            "hfqtl_df (9880, 19)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "1913it [00:14, 133.96it/s]\n",
            "1913it [00:00, 6196.88it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hffinal_df (2809, 28)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "993it [00:04, 230.00it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# QTL Analysis - Hereford : Nelore\n",
        "\n",
        "import pandas as pd\n",
        "import shutil\n",
        "\n",
        "chr=[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,\"X\"]\n",
        "# chr=[1]\n",
        "for i in chr:\n",
        "  print(f\"Chromosome{i}\")\n",
        "\n",
        "  # set the file path\n",
        "  inp_f1=f'/content/drive/MyDrive/Hereford_VarAnalysis/Hereford_chrVar/del/{i}/hfqtl_NelVar{i}.csv'\n",
        "  outp_loc=f\"/content/drive/MyDrive/Hereford_VarAnalysis/Hereford_chrVar/del/{i}\"\n",
        "\n",
        "  # read the file\n",
        "  dff=pd.read_csv(inp_f1)\n",
        "  # print(in_f1)\n",
        "  print(\"file:\", dff.shape)\n",
        "  # print(df)\n",
        "\n",
        "  # filter the LOV has greater than equal to 10\n",
        "  filter_lov10=dff[dff[\"LOV\"]>=10]\n",
        "\n",
        "  # ignore the qtl class has nil value\n",
        "  filter_qtl=filter_lov10[filter_lov10[\"QTL Class\"]!=\"Nil\"]\n",
        "  print(\"filter_qtl:\", filter_qtl.shape)\n",
        "\n",
        "  # filter the qtlgenetype has within gene type\n",
        "  filter_qtl=filter_qtl[filter_qtl[\"qtlgene_type\"]==\"within_gene\"]\n",
        "  filter_qtl.shape\n",
        "  print(\"filter_qtl:\", filter_qtl.shape)\n",
        "\n",
        "  # filter the HFgenetype has within gene type\n",
        "  filter_hf=filter_qtl[filter_qtl[\"HFgene_type\"]==\"within_gene\"]\n",
        "  filter_hf.shape\n",
        "  print(\"filte_hf:\", filter_hf.shape)\n",
        "\n",
        "  # filter the Nelgenetype has within gene type\n",
        "  filter_nel=filter_hf[filter_hf[\"Nelgene_type\"]==\"within_gene\"]\n",
        "  filter_nel.shape\n",
        "  print(\"filter_nel:\", filter_nel.shape)\n",
        "\n",
        "  filter_nel=filter_nel.drop_duplicates(subset=[\"Symbol\", \"QTL Class\", \"startpos.q\", \"endpos.q\", \"LOV\"]).reset_index()\n",
        "  filter_nelq=filter_nel.groupby([\"Name\", \"Symbol\", \"NelLocus\", \"NelProt\", \"startpos.q\", \"endpos.q\", \"LOV\"]).agg({\"QTL Class\": lambda x: \",\".join(set(x))}).reset_index()\n",
        "\n",
        "  # Group by 'Name' and 'Symbol' and aggregate the sum of 'LOV' and join 'QTL Class'\n",
        "  del_qtlHN=filter_nelq.groupby([\"Symbol\", \"Name\", \"NelLocus\", \"NelProt\", \"LOV\"]).agg({\"QTL Class\": \",\".join}).reset_index()\n",
        "\n",
        "  # Drop duplicate values in the 'QTL Class' column\n",
        "  del_qtlHN['QTL Class'] = del_qtlHN['QTL Class'].apply(lambda x: ', '.join(pd.unique(x.split(','))))\n",
        "\n",
        "  # save the file into destination\n",
        "  out_f1=f\"del_qtlHN{i}.csv\"\n",
        "  del_qtlHN.to_csv(out_f1)\n",
        "  print(\"del_qtlHN:\", del_qtlHN.shape)\n",
        "  shutil.copy(out_f1, outp_loc)\n",
        "\n",
        "  # Save the file into destination\n",
        "  del_qtlHN50=del_qtlHN[del_qtlHN[\"LOV\"]>=50]\n",
        "  out_f2=f\"del_qtl50HN{i}.csv\"\n",
        "  del_qtlHN50.to_csv(out_f2)\n",
        "  print(\"del_qtlHN50:\", del_qtlHN50.shape)\n",
        "  shutil.copy(out_f2, outp_loc)"
      ],
      "metadata": {
        "id": "48Yg7SodTCSp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "61cbf1b7-9b89-4e92-e919-67d9528db1cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Chromosome1\n",
            "file: (3433, 36)\n",
            "filter_qtl: (80, 36)\n",
            "filter_qtl: (36, 36)\n",
            "filte_hf: (34, 36)\n",
            "filter_nel: (34, 36)\n",
            "del_qtlHN: (6, 6)\n",
            "del_qtlHN50: (0, 6)\n",
            "Chromosome2\n",
            "file: (2580, 36)\n",
            "filter_qtl: (111, 36)\n",
            "filter_qtl: (82, 36)\n",
            "filte_hf: (81, 36)\n",
            "filter_nel: (75, 36)\n",
            "del_qtlHN: (9, 6)\n",
            "del_qtlHN50: (2, 6)\n",
            "Chromosome3\n",
            "file: (2346, 36)\n",
            "filter_qtl: (60, 36)\n",
            "filter_qtl: (28, 36)\n",
            "filte_hf: (27, 36)\n",
            "filter_nel: (26, 36)\n",
            "del_qtlHN: (11, 6)\n",
            "del_qtlHN50: (0, 6)\n",
            "Chromosome4\n",
            "file: (3622, 36)\n",
            "filter_qtl: (85, 36)\n",
            "filter_qtl: (56, 36)\n",
            "filte_hf: (55, 36)\n",
            "filter_nel: (34, 36)\n",
            "del_qtlHN: (12, 6)\n",
            "del_qtlHN50: (1, 6)\n",
            "Chromosome5\n",
            "file: (1728, 36)\n",
            "filter_qtl: (34, 36)\n",
            "filter_qtl: (28, 36)\n",
            "filte_hf: (26, 36)\n",
            "filter_nel: (15, 36)\n",
            "del_qtlHN: (3, 6)\n",
            "del_qtlHN50: (0, 6)\n",
            "Chromosome6\n",
            "file: (3873, 36)\n",
            "filter_qtl: (128, 36)\n",
            "filter_qtl: (106, 36)\n",
            "filte_hf: (93, 36)\n",
            "filter_nel: (85, 36)\n",
            "del_qtlHN: (14, 6)\n",
            "del_qtlHN50: (1, 6)\n",
            "Chromosome7\n",
            "file: (3040, 36)\n",
            "filter_qtl: (40, 36)\n",
            "filter_qtl: (22, 36)\n",
            "filte_hf: (19, 36)\n",
            "filter_nel: (11, 36)\n",
            "del_qtlHN: (3, 6)\n",
            "del_qtlHN50: (0, 6)\n",
            "Chromosome8\n",
            "file: (3163, 36)\n",
            "filter_qtl: (74, 36)\n",
            "filter_qtl: (55, 36)\n",
            "filte_hf: (52, 36)\n",
            "filter_nel: (40, 36)\n",
            "del_qtlHN: (8, 6)\n",
            "del_qtlHN50: (1, 6)\n",
            "Chromosome9\n",
            "file: (1887, 36)\n",
            "filter_qtl: (30, 36)\n",
            "filter_qtl: (22, 36)\n",
            "filte_hf: (21, 36)\n",
            "filter_nel: (17, 36)\n",
            "del_qtlHN: (2, 6)\n",
            "del_qtlHN50: (0, 6)\n",
            "Chromosome10\n",
            "file: (4382, 36)\n",
            "filter_qtl: (48, 36)\n",
            "filter_qtl: (28, 36)\n",
            "filte_hf: (27, 36)\n",
            "filter_nel: (22, 36)\n",
            "del_qtlHN: (4, 6)\n",
            "del_qtlHN50: (0, 6)\n",
            "Chromosome11\n",
            "file: (2970, 36)\n",
            "filter_qtl: (79, 36)\n",
            "filter_qtl: (62, 36)\n",
            "filte_hf: (62, 36)\n",
            "filter_nel: (61, 36)\n",
            "del_qtlHN: (4, 6)\n",
            "del_qtlHN50: (0, 6)\n",
            "Chromosome12\n",
            "file: (1972, 36)\n",
            "filter_qtl: (113, 36)\n",
            "filter_qtl: (98, 36)\n",
            "filte_hf: (95, 36)\n",
            "filter_nel: (91, 36)\n",
            "del_qtlHN: (10, 6)\n",
            "del_qtlHN50: (1, 6)\n",
            "Chromosome13\n",
            "file: (2124, 36)\n",
            "filter_qtl: (47, 36)\n",
            "filter_qtl: (32, 36)\n",
            "filte_hf: (29, 36)\n",
            "filter_nel: (26, 36)\n",
            "del_qtlHN: (7, 6)\n",
            "del_qtlHN50: (2, 6)\n",
            "Chromosome14\n",
            "file: (1759, 36)\n",
            "filter_qtl: (46, 36)\n",
            "filter_qtl: (16, 36)\n",
            "filte_hf: (13, 36)\n",
            "filter_nel: (13, 36)\n",
            "del_qtlHN: (6, 6)\n",
            "del_qtlHN50: (1, 6)\n",
            "Chromosome15\n",
            "file: (2082, 36)\n",
            "filter_qtl: (65, 36)\n",
            "filter_qtl: (33, 36)\n",
            "filte_hf: (31, 36)\n",
            "filter_nel: (24, 36)\n",
            "del_qtlHN: (6, 6)\n",
            "del_qtlHN50: (0, 6)\n",
            "Chromosome16\n",
            "file: (2108, 36)\n",
            "filter_qtl: (46, 36)\n",
            "filter_qtl: (24, 36)\n",
            "filte_hf: (21, 36)\n",
            "filter_nel: (18, 36)\n",
            "del_qtlHN: (5, 6)\n",
            "del_qtlHN50: (0, 6)\n",
            "Chromosome17\n",
            "file: (1662, 36)\n",
            "filter_qtl: (17, 36)\n",
            "filter_qtl: (11, 36)\n",
            "filte_hf: (11, 36)\n",
            "filter_nel: (9, 36)\n",
            "del_qtlHN: (2, 6)\n",
            "del_qtlHN50: (0, 6)\n",
            "Chromosome18\n",
            "file: (1268, 36)\n",
            "filter_qtl: (19, 36)\n",
            "filter_qtl: (11, 36)\n",
            "filte_hf: (11, 36)\n",
            "filter_nel: (10, 36)\n",
            "del_qtlHN: (6, 6)\n",
            "del_qtlHN50: (2, 6)\n",
            "Chromosome19\n",
            "file: (1562, 36)\n",
            "filter_qtl: (49, 36)\n",
            "filter_qtl: (43, 36)\n",
            "filte_hf: (42, 36)\n",
            "filter_nel: (32, 36)\n",
            "del_qtlHN: (6, 6)\n",
            "del_qtlHN50: (2, 6)\n",
            "Chromosome20\n",
            "file: (2154, 36)\n",
            "filter_qtl: (67, 36)\n",
            "filter_qtl: (30, 36)\n",
            "filte_hf: (15, 36)\n",
            "filter_nel: (2, 36)\n",
            "del_qtlHN: (1, 6)\n",
            "del_qtlHN50: (0, 6)\n",
            "Chromosome21\n",
            "file: (1186, 36)\n",
            "filter_qtl: (24, 36)\n",
            "filter_qtl: (16, 36)\n",
            "filte_hf: (15, 36)\n",
            "filter_nel: (15, 36)\n",
            "del_qtlHN: (3, 6)\n",
            "del_qtlHN50: (0, 6)\n",
            "Chromosome22\n",
            "file: (2557, 36)\n",
            "filter_qtl: (126, 36)\n",
            "filter_qtl: (117, 36)\n",
            "filte_hf: (111, 36)\n",
            "filter_nel: (106, 36)\n",
            "del_qtlHN: (4, 6)\n",
            "del_qtlHN50: (0, 6)\n",
            "Chromosome23\n",
            "file: (1006, 36)\n",
            "filter_qtl: (35, 36)\n",
            "filter_qtl: (26, 36)\n",
            "filte_hf: (26, 36)\n",
            "filter_nel: (23, 36)\n",
            "del_qtlHN: (7, 6)\n",
            "del_qtlHN50: (5, 6)\n",
            "Chromosome24\n",
            "file: (884, 36)\n",
            "filter_qtl: (42, 36)\n",
            "filter_qtl: (13, 36)\n",
            "filte_hf: (11, 36)\n",
            "filter_nel: (11, 36)\n",
            "del_qtlHN: (3, 6)\n",
            "del_qtlHN50: (1, 6)\n",
            "Chromosome25\n",
            "file: (1229, 36)\n",
            "filter_qtl: (24, 36)\n",
            "filter_qtl: (20, 36)\n",
            "filte_hf: (20, 36)\n",
            "filter_nel: (20, 36)\n",
            "del_qtlHN: (2, 6)\n",
            "del_qtlHN50: (0, 6)\n",
            "Chromosome26\n",
            "file: (4115, 36)\n",
            "filter_qtl: (23, 36)\n",
            "filter_qtl: (9, 36)\n",
            "filte_hf: (9, 36)\n",
            "filter_nel: (9, 36)\n",
            "del_qtlHN: (4, 6)\n",
            "del_qtlHN50: (1, 6)\n",
            "Chromosome27\n",
            "file: (1092, 36)\n",
            "filter_qtl: (26, 36)\n",
            "filter_qtl: (17, 36)\n",
            "filte_hf: (17, 36)\n",
            "filter_nel: (0, 36)\n",
            "del_qtlHN: (0, 6)\n",
            "del_qtlHN50: (0, 6)\n",
            "Chromosome28\n",
            "file: (1241, 36)\n",
            "filter_qtl: (36, 36)\n",
            "filter_qtl: (34, 36)\n",
            "filte_hf: (32, 36)\n",
            "filter_nel: (28, 36)\n",
            "del_qtlHN: (3, 6)\n",
            "del_qtlHN50: (1, 6)\n",
            "Chromosome29\n",
            "file: (2101, 36)\n",
            "filter_qtl: (97, 36)\n",
            "filter_qtl: (75, 36)\n",
            "filte_hf: (72, 36)\n",
            "filter_nel: (48, 36)\n",
            "del_qtlHN: (5, 6)\n",
            "del_qtlHN50: (1, 6)\n",
            "ChromosomeX\n",
            "file: (4124, 36)\n",
            "filter_qtl: (9, 36)\n",
            "filter_qtl: (8, 36)\n",
            "filte_hf: (8, 36)\n",
            "filter_nel: (7, 36)\n",
            "del_qtlHN: (2, 6)\n",
            "del_qtlHN50: (0, 6)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Table preparation\n",
        "\n",
        "# Table preparations\n",
        "\n",
        "f1=pd.read_csv(\"/content/drive/MyDrive/Hereford_VarAnalysis/Hereford_chrVar/del/1/del_qtl50HN1.csv\")\n",
        "f2=pd.read_csv(\"/content/drive/MyDrive/Hereford_VarAnalysis/Hereford_chrVar/del/2/del_qtl50HN2.csv\")\n",
        "f3=pd.read_csv(\"/content/drive/MyDrive/Hereford_VarAnalysis/Hereford_chrVar/del/3/del_qtl50HN3.csv\")\n",
        "f4=pd.read_csv(\"/content/drive/MyDrive/Hereford_VarAnalysis/Hereford_chrVar/del/4/del_qtl50HN4.csv\")\n",
        "f5=pd.read_csv(\"/content/drive/MyDrive/Hereford_VarAnalysis/Hereford_chrVar/del/5/del_qtl50HN5.csv\")\n",
        "f6=pd.read_csv(\"/content/drive/MyDrive/Hereford_VarAnalysis/Hereford_chrVar/del/6/del_qtl50HN6.csv\")\n",
        "f7=pd.read_csv(\"/content/drive/MyDrive/Hereford_VarAnalysis/Hereford_chrVar/del/7/del_qtl50HN7.csv\")\n",
        "f8=pd.read_csv(\"/content/drive/MyDrive/Hereford_VarAnalysis/Hereford_chrVar/del/8/del_qtl50HN8.csv\")\n",
        "f9=pd.read_csv(\"/content/drive/MyDrive/Hereford_VarAnalysis/Hereford_chrVar/del/9/del_qtl50HN9.csv\")\n",
        "f10=pd.read_csv(\"/content/drive/MyDrive/Hereford_VarAnalysis/Hereford_chrVar/del/10/del_qtl50HN10.csv\")\n",
        "f11=pd.read_csv(\"/content/drive/MyDrive/Hereford_VarAnalysis/Hereford_chrVar/del/11/del_qtl50HN11.csv\")\n",
        "f12=pd.read_csv(\"/content/drive/MyDrive/Hereford_VarAnalysis/Hereford_chrVar/del/12/del_qtl50HN12.csv\")\n",
        "f13=pd.read_csv(\"/content/drive/MyDrive/Hereford_VarAnalysis/Hereford_chrVar/del/13/del_qtl50HN13.csv\")\n",
        "f14=pd.read_csv(\"/content/drive/MyDrive/Hereford_VarAnalysis/Hereford_chrVar/del/14/del_qtl50HN14.csv\")\n",
        "f15=pd.read_csv(\"/content/drive/MyDrive/Hereford_VarAnalysis/Hereford_chrVar/del/15/del_qtl50HN15.csv\")\n",
        "f16=pd.read_csv(\"/content/drive/MyDrive/Hereford_VarAnalysis/Hereford_chrVar/del/16/del_qtl50HN16.csv\")\n",
        "f17=pd.read_csv(\"/content/drive/MyDrive/Hereford_VarAnalysis/Hereford_chrVar/del/17/del_qtl50HN17.csv\")\n",
        "f18=pd.read_csv(\"/content/drive/MyDrive/Hereford_VarAnalysis/Hereford_chrVar/del/18/del_qtl50HN18.csv\")\n",
        "f19=pd.read_csv(\"/content/drive/MyDrive/Hereford_VarAnalysis/Hereford_chrVar/del/19/del_qtl50HN19.csv\")\n",
        "f20=pd.read_csv(\"/content/drive/MyDrive/Hereford_VarAnalysis/Hereford_chrVar/del/20/del_qtl50HN20.csv\")\n",
        "f21=pd.read_csv(\"/content/drive/MyDrive/Hereford_VarAnalysis/Hereford_chrVar/del/21/del_qtl50HN21.csv\")\n",
        "f22=pd.read_csv(\"/content/drive/MyDrive/Hereford_VarAnalysis/Hereford_chrVar/del/22/del_qtl50HN22.csv\")\n",
        "f23=pd.read_csv(\"/content/drive/MyDrive/Hereford_VarAnalysis/Hereford_chrVar/del/23/del_qtl50HN23.csv\")\n",
        "f24=pd.read_csv(\"/content/drive/MyDrive/Hereford_VarAnalysis/Hereford_chrVar/del/24/del_qtl50HN24.csv\")\n",
        "f25=pd.read_csv(\"/content/drive/MyDrive/Hereford_VarAnalysis/Hereford_chrVar/del/25/del_qtl50HN25.csv\")\n",
        "f26=pd.read_csv(\"/content/drive/MyDrive/Hereford_VarAnalysis/Hereford_chrVar/del/26/del_qtl50HN26.csv\")\n",
        "f27=pd.read_csv(\"/content/drive/MyDrive/Hereford_VarAnalysis/Hereford_chrVar/del/27/del_qtl50HN27.csv\")\n",
        "f28=pd.read_csv(\"/content/drive/MyDrive/Hereford_VarAnalysis/Hereford_chrVar/del/28/del_qtl50HN28.csv\")\n",
        "f29=pd.read_csv(\"/content/drive/MyDrive/Hereford_VarAnalysis/Hereford_chrVar/del/29/del_qtl50HN29.csv\")\n",
        "fX=pd.read_csv(\"/content/drive/MyDrive/Hereford_VarAnalysis/Hereford_chrVar/del/X/del_qtl50HNX.csv\")"
      ],
      "metadata": {
        "id": "M95sSlmoe01e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "table_delqtl50HN=pd.DataFrame(columns=[\"Chromosome number\"]+list(f1))"
      ],
      "metadata": {
        "id": "WpgZSpsffu1x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "f1[\"Chromosome number\"]=1\n",
        "f2[\"Chromosome number\"]=2\n",
        "f3[\"Chromosome number\"]=3\n",
        "f4[\"Chromosome number\"]=4\n",
        "f5[\"Chromosome number\"]=5\n",
        "f6[\"Chromosome number\"]=6\n",
        "f7[\"Chromosome number\"]=7\n",
        "f8[\"Chromosome number\"]=8\n",
        "f9[\"Chromosome number\"]=9\n",
        "f10[\"Chromosome number\"]=10\n",
        "f11[\"Chromosome number\"]=11\n",
        "f12[\"Chromosome number\"]=12\n",
        "f13[\"Chromosome number\"]=13\n",
        "f14[\"Chromosome number\"]=14\n",
        "f15[\"Chromosome number\"]=15\n",
        "f16[\"Chromosome number\"]=16\n",
        "f17[\"Chromosome number\"]=17\n",
        "f18[\"Chromosome number\"]=18\n",
        "f19[\"Chromosome number\"]=19\n",
        "f20[\"Chromosome number\"]=20\n",
        "f21[\"Chromosome number\"]=21\n",
        "f22[\"Chromosome number\"]=22\n",
        "f23[\"Chromosome number\"]=23\n",
        "f24[\"Chromosome number\"]=24\n",
        "f25[\"Chromosome number\"]=25\n",
        "f26[\"Chromosome number\"]=26\n",
        "f27[\"Chromosome number\"]=27\n",
        "f28[\"Chromosome number\"]=28\n",
        "f29[\"Chromosome number\"]=29\n",
        "fX[\"Chromosome number\"]=\"X\""
      ],
      "metadata": {
        "id": "mvKFyOj9fwo4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "table_delqtl50HN=pd.concat([table_delqtl50HN, f1, f2, f3, f4, f5, f6, f7, f8, f9, f10, f11, f12, f13, f14, f15, f16, f17, f18, f19, f20, f21, f22, f23, f24, f25, f26, f27, f28, f29, fX])\n"
      ],
      "metadata": {
        "id": "9xDXcVRPfzZ8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "table_delqtl50HN.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-B9iQOVlf5vr",
        "outputId": "a50e847d-1ad0-46bf-ab17-4fca3168c151"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(22, 8)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "table_delqtl50HN.to_csv(\"table_delqtl50HN.csv\")\n",
        "shutil.copy(\"table_delqtl50HN.csv\", \"/content/drive/MyDrive/Hereford_VarAnalysis/Hereford_chrVar\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "X93nfsmzgLrK",
        "outputId": "cea81b68-f5db-43e3-d36e-cae3fd544e1f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/MyDrive/Hereford_VarAnalysis/Hereford_chrVar/table_delqtl50HN.csv'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
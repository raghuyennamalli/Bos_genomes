{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "90qDRfe4pWc5",
        "outputId": "4a218242-a3b4-42aa-8294-f599d0d81cff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Substitution\n",
        "def indicineprotvar(hfprotvar_wd, chr, outloc):\n",
        "  print(\"hffinal_df\", hfprotvar_wd.shape)\n",
        "  in_f1=f\"/content/drive/MyDrive/gene_ext/ind_protein/ind_chr{chr}_prot.csv\"\n",
        "  ind_prot=pd.read_csv(in_f1)\n",
        "  ind_prot[\"indstart_of_next_gene\"] = ind_prot[\"Start\"].shift(-1).fillna(0)\n",
        "  finalindprot_df=pd.DataFrame(columns=list(hfprotvar_wd)+[\"NelStart\"]+[\"NelStop\"]+[\"NelLocus\"]+[\"NelLength\"]+[\"NelProt\"]+[\"Nelnextgen\"]+[\"Nelgene_type\"])\n",
        "  for i, row in tqdm(ind_prot.iterrows()):\n",
        "    # Check for the at start\n",
        "    if hfprotvar_wd[(row[\"Start\"]==hfprotvar_wd[\"startpos.q\"]) & (row[\"Stop\"]>hfprotvar_wd[\"endpos.q\"])].shape[0]>=1:\n",
        "        tmp_df = hfprotvar_wd[(row[\"Start\"]==hfprotvar_wd[\"startpos.q\"]) & (row[\"Stop\"]>hfprotvar_wd[\"endpos.q\"])].copy(deep=True)\n",
        "        tmp_df[\"Nelgene_type\"] = \"at_start\"\n",
        "        tmp_df[\"NelStart\"] = row[\"Start\"]\n",
        "        tmp_df[\"NelStop\"] = row[\"Stop\"]\n",
        "        tmp_df[\"NelLocus\"] = row[\"Locus\"]\n",
        "        tmp_df[\"NelLength\"] = row[\"Length\"]\n",
        "        tmp_df[\"NelProt\"] = row[\"Protein Name\"]\n",
        "        tmp_df[\"Nelnextgen\"] = row[\"indstart_of_next_gene\"]\n",
        "        finalindprot_df = pd.concat([finalindprot_df,tmp_df]).reset_index(drop=True)\n",
        "    # check for the at end\n",
        "    elif hfprotvar_wd[(row[\"Start\"]<hfprotvar_wd[\"startpos.q\"]) & (row[\"Stop\"]==hfprotvar_wd[\"endpos.q\"])].shape[0]>=1:\n",
        "        tmp_df = hfprotvar_wd[(row[\"Start\"]<hfprotvar_wd[\"startpos.q\"]) & (row[\"Stop\"]==hfprotvar_wd[\"endpos.q\"])].copy(deep=True)\n",
        "        tmp_df[\"Nelgene_type\"] = \"at_end\"\n",
        "        tmp_df[\"NelStart\"] = row[\"Start\"]\n",
        "        tmp_df[\"NelStop\"] = row[\"Stop\"]\n",
        "        tmp_df[\"NelLocus\"] = row[\"Locus\"]\n",
        "        tmp_df[\"NelLength\"] = row[\"Length\"]\n",
        "        tmp_df[\"NelProt\"] = row[\"Protein Name\"]\n",
        "        tmp_df[\"Nelnextgen\"] = row[\"indstart_of_next_gene\"]\n",
        "        finalindprot_df = pd.concat([finalindprot_df,tmp_df]).reset_index(drop=True)\n",
        "    # Check for the within gene\n",
        "    elif hfprotvar_wd[(row[\"Start\"]<hfprotvar_wd[\"startpos.q\"]) & (row[\"Stop\"]>hfprotvar_wd[\"endpos.q\"])].shape[0]>=1:\n",
        "        tmp_df = hfprotvar_wd[(row[\"Start\"]<hfprotvar_wd[\"startpos.q\"]) & (row[\"Stop\"]>hfprotvar_wd[\"endpos.q\"])].copy(deep=True)\n",
        "        tmp_df[\"Nelgene_type\"] = \"within_gene\"\n",
        "        tmp_df[\"NelStart\"] = row[\"Start\"]\n",
        "        tmp_df[\"NelStop\"] = row[\"Stop\"]\n",
        "        tmp_df[\"NelLocus\"] = row[\"Locus\"]\n",
        "        tmp_df[\"NelLength\"] = row[\"Length\"]\n",
        "        tmp_df[\"NelProt\"] = row[\"Protein Name\"]\n",
        "        tmp_df[\"Nelnextgen\"] = row[\"indstart_of_next_gene\"]\n",
        "        finalindprot_df = pd.concat([finalindprot_df,tmp_df]).reset_index(drop=True)\n",
        "    # Check for the intergenic gene\n",
        "    elif hfprotvar_wd[(row[\"Stop\"]<hfprotvar_wd[\"startpos.q\"]) & (row[\"indstart_of_next_gene\"]>hfprotvar_wd[\"endpos.q\"])].shape[0]>=1:\n",
        "        tmp_df = hfprotvar_wd[(row[\"Stop\"]<hfprotvar_wd[\"startpos.q\"]) & (row[\"indstart_of_next_gene\"]>hfprotvar_wd[\"endpos.q\"])].copy(deep=True)\n",
        "        tmp_df[\"Nelgene_type\"] = \"intergenic_gene\"\n",
        "        tmp_df[\"NelStart\"] = row[\"Start\"]\n",
        "        tmp_df[\"NelStop\"] = row[\"Stop\"]\n",
        "        tmp_df[\"NelLocus\"] = row[\"Locus\"]\n",
        "        tmp_df[\"NelLength\"] = row[\"Length\"]\n",
        "        tmp_df[\"NelProt\"] = row[\"Protein Name\"]\n",
        "        tmp_df[\"Nelnextgen\"] = row[\"indstart_of_next_gene\"]\n",
        "        finalindprot_df = pd.concat([finalindprot_df,tmp_df]).reset_index(drop=True)\n",
        "    else:\n",
        "        pass\n",
        "\n",
        "\n",
        "  # Generate output file\n",
        "  out_file13=f\"hfqtl_NelVar{chr}.csv\"\n",
        "  finalindprot_df.to_csv(out_file13)\n",
        "  shutil.copy(out_file13, outloc)\n",
        "\n",
        "  # extract only the immune genes\n",
        "  hfimm_nel = pd.DataFrame\n",
        "  hfimm_nel=finalindprot_df[finalindprot_df[\"keyword_found\"]==True]\n",
        "  out_file14=f\"hfimm_nel{chr}.csv\"\n",
        "  hfimm_nel.to_csv(out_file14)\n",
        "  shutil.copy(out_file14, outloc)\n",
        "\n",
        "  # LOV50\n",
        "  hfNel_LOV50=finalindprot_df[finalindprot_df[\"LOV\"]>=50]\n",
        "  hfNelimm_LOV50=hfimm_nel[hfimm_nel[\"LOV\"]>=50]\n",
        "  out_file15=f\"hfNel_LOV50_{chr}.csv\"\n",
        "  out_file16=f\"hfNelimm_LOV50_{chr}.csv\"\n",
        "  hfNel_LOV50.to_csv(out_file15)\n",
        "  hfNelimm_LOV50.to_csv(out_file16)\n",
        "  shutil.copy(out_file15, outloc)\n",
        "  shutil.copy(out_file16, outloc)\n"
      ],
      "metadata": {
        "id": "GVFTvduBCx2Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def hfqtl_VarAnal(common_df, hfqtl_df, chr, outloc):\n",
        "  # Identifying the variations\n",
        "  hfqtl_df.reset_index(drop=True, inplace=True)\n",
        "  common_df.reset_index(drop=True, inplace=True)\n",
        "  final_df = pd.DataFrame(columns=list(hfqtl_df.columns)+[\"HFgene_type\"]+[\"startpos.r\"]+[\"endpos.r\"]+[\"startpos.q\"]+[\"endpos.q\"]+[\"seq.r\"]+[\"seq.q\"]+[\"LOV\"])\n",
        "  for i, row in tqdm(hfqtl_df.iterrows()):\n",
        "    # Check for the at start\n",
        "    if hfqtl_df[(row[\"Begin\"]==common_df[\"startpos.r\"]) & (row[\"End\"]>common_df[\"endpos.r\"])].shape[0]>=1:\n",
        "        tmp_df = hfqtl_df.loc[(row[\"Begin\"]==common_df[\"startpos.r\"]) & (row[\"End\"]>common_df[\"endpos.r\"]), :].copy(deep=True)\n",
        "        tmp_df[\"HFgene_type\"] = \"at_start\"\n",
        "        tmp_df[\"startpos.r\"] = common_df[\"startpos.r\"]\n",
        "        tmp_df[\"endpos.r\"] = common_df[\"endpos.r\"]\n",
        "        tmp_df[\"startpos.q\"] = common_df[\"startpos.q\"]\n",
        "        tmp_df[\"endpos.q\"] = common_df[\"endpos.q\"]\n",
        "        tmp_df[\"seq.r\"] = common_df[\"seq.r\"]\n",
        "        tmp_df[\"seq.q\"] = common_df[\"seq.q\"]\n",
        "        tmp_df[\"LOV\"] = common_df[\"LOV\"]\n",
        "        final_df = pd.concat([final_df,tmp_df]).reset_index(drop=True)\n",
        "    # check for the at end\n",
        "    elif hfqtl_df[(row[\"Begin\"]<common_df[\"startpos.r\"]) & (row[\"End\"]==common_df[\"endpos.r\"])].shape[0]>=1:\n",
        "        tmp_df = hfqtl_df.loc[(row[\"Begin\"]<common_df[\"startpos.r\"]) & (row[\"End\"]==common_df[\"endpos.r\"]), :].copy(deep=True)\n",
        "        tmp_df[\"HFgene_type\"] = \"at_end\"\n",
        "        tmp_df[\"startpos.r\"] = common_df[\"startpos.r\"]\n",
        "        tmp_df[\"endpos.r\"] = common_df[\"endpos.r\"]\n",
        "        tmp_df[\"startpos.q\"] = common_df[\"startpos.q\"]\n",
        "        tmp_df[\"endpos.q\"] = common_df[\"endpos.q\"]\n",
        "        tmp_df[\"seq.r\"] = common_df[\"seq.r\"]\n",
        "        tmp_df[\"seq.q\"] = common_df[\"seq.q\"]\n",
        "        tmp_df[\"LOV\"] = common_df[\"LOV\"]\n",
        "        final_df = pd.concat([final_df,tmp_df]).reset_index(drop=True)\n",
        "    # Check for the within gene\n",
        "    elif hfqtl_df[(row[\"Begin\"]<common_df[\"startpos.r\"]) & (row[\"End\"]>common_df[\"endpos.r\"])].shape[0]>=1:\n",
        "        tmp_df = hfqtl_df.loc[(row[\"Begin\"]<common_df[\"startpos.r\"]) & (row[\"End\"]>common_df[\"endpos.r\"]), :].copy(deep=True)\n",
        "        tmp_df[\"HFgene_type\"] = \"within_gene\"\n",
        "        tmp_df[\"startpos.r\"] = common_df[\"startpos.r\"]\n",
        "        tmp_df[\"endpos.r\"] = common_df[\"endpos.r\"]\n",
        "        tmp_df[\"startpos.q\"] = common_df[\"startpos.q\"]\n",
        "        tmp_df[\"endpos.q\"] = common_df[\"endpos.q\"]\n",
        "        tmp_df[\"seq.r\"] = common_df[\"seq.r\"]\n",
        "        tmp_df[\"seq.q\"] = common_df[\"seq.q\"]\n",
        "        tmp_df[\"LOV\"] = common_df[\"LOV\"]\n",
        "        final_df = pd.concat([final_df,tmp_df]).reset_index(drop=True)\n",
        "    # Check for the intergenic gene\n",
        "    elif hfqtl_df[(row[\"End\"]<common_df[\"startpos.r\"]) & (row[\"hfstart_of_next_gene\"]>common_df[\"endpos.r\"])].shape[0]>=1:\n",
        "        tmp_df = hfqtl_df.loc[(row[\"End\"]<common_df[\"startpos.r\"]) & (row[\"hfstart_of_next_gene\"]>common_df[\"endpos.r\"]), :].copy(deep=True)\n",
        "        tmp_df[\"HFgene_type\"] = \"intergenic_gene\"\n",
        "        tmp_df[\"startpos.r\"] = common_df[\"startpos.r\"]\n",
        "        tmp_df[\"endpos.r\"] = common_df[\"endpos.r\"]\n",
        "        tmp_df[\"startpos.q\"] = common_df[\"startpos.q\"]\n",
        "        tmp_df[\"endpos.q\"] = common_df[\"endpos.q\"]\n",
        "        tmp_df[\"seq.r\"] = common_df[\"seq.r\"]\n",
        "        tmp_df[\"seq.q\"] = common_df[\"seq.q\"]\n",
        "        tmp_df[\"LOV\"] = common_df[\"LOV\"]\n",
        "        final_df = pd.concat([final_df,tmp_df]).reset_index(drop=True)\n",
        "    else:\n",
        "        pass\n",
        "\n",
        "  # Generate output file\n",
        "  out_file1=f\"hfprotvar{chr}.csv\"\n",
        "  final_df.to_csv(out_file1)\n",
        "  print(\"final_df\", len(final_df))\n",
        "  # shutil.copy(out_file1, outloc)\n",
        "\n",
        "  # find variation not present in gene and intergene region called as other non coding region\n",
        "  final_df1 = pd.DataFrame(columns=common_df.columns)\n",
        "  for index, row in tqdm(final_df.iterrows()):\n",
        "    # Check if 'startpos.q' is present in any row of file2\n",
        "    if row['startpos.q'] not in common_df['startpos.q'].values:\n",
        "        # Append the row to the DataFrame if not found\n",
        "        final_df1 = final_df1.append(row, ignore_index=True)\n",
        "\n",
        "  # Save the DataFrame with rows not found in file2 to a new CSV file\n",
        "  out_file2=f\"non_coding{chr}.csv\"\n",
        "  final_df1.to_csv(out_file2, index=False)\n",
        "  print(\"final_df1\", len(final_df1))\n",
        "  # shutil.copy(out_file2, outloc)\n",
        "\n",
        "  # # remove duplicates\n",
        "  # hfprotvar_wd = final_df.drop_duplicates(subset=['Symbol', \"QTL Class\", 'startpos.r', 'endpos.r'])\n",
        "  # out_file_1=f\"hfprotvar{chr}.csv\"\n",
        "  # hfprotvar_wd.to_csv(out_file_1)\n",
        "  # shutil.copy(out_file_1, outloc)\n",
        "\n",
        "  # # extract only the immune genes\n",
        "  # hfimm = pd.DataFrame\n",
        "  # hfimm=hfprotvar_wd[hfprotvar_wd[\"keyword_found\"]==True]\n",
        "  # out_file3=f\"hfimm{chr}.csv\"\n",
        "  # hfimm.to_csv(out_file3)\n",
        "  # shutil.copy(out_file3, outloc)\n",
        "\n",
        "  # # Extract the variation presents in gene and intergene seperately\n",
        "  # hf_within_gene=hfprotvar_wd[hfprotvar_wd[\"HFgene_type\"]==\"within_gene\"]\n",
        "  # hf_inter_gene=hfprotvar_wd[hfprotvar_wd[\"HFgene_type\"]==\"intergenic_gene\"]\n",
        "\n",
        "  # # extract the variations among genomic regions including gene and intergene has greater the 50 LOV (length of varaition)\n",
        "  # hf_LOV50=hfprotvar_wd[hfprotvar_wd[\"LOV\"]>=50]\n",
        "\n",
        "  # out_file4=f\"hf_within_gene{chr}.csv\"\n",
        "  # out_file5=f\"hf_inter_gene{chr}.csv\"\n",
        "  # out_file6=f\"hf_LOV50_{chr}.csv\"\n",
        "\n",
        "  # hf_within_gene.to_csv(out_file4)\n",
        "  # hf_inter_gene.to_csv(out_file5)\n",
        "  # hf_LOV50.to_csv(out_file6)\n",
        "\n",
        "  # shutil.copy(out_file4, outloc)\n",
        "  # shutil.copy(out_file5, outloc)\n",
        "  # shutil.copy(out_file6, outloc)\n",
        "\n",
        "  # # Extract the variation presents in immune gene and intergene seperately\n",
        "  # hfimm_within_gene=hfimm[hfimm[\"HFgene_type\"]==\"within_gene\"]\n",
        "  # hfimm_inter_gene=hfimm[hfimm[\"HFgene_type\"]==\"intergenic_gene\"]\n",
        "\n",
        "  # # extract the variations among genomic regions including gene and intergene has greater the 50 LOV (length of varaition)\n",
        "  # hfimm_LOV50=hfimm[hfimm[\"LOV\"]>=50]\n",
        "\n",
        "  # out_file7=f\"hfimm_within_gene{chr}.csv\"\n",
        "  # out_file8=f\"hfimm_inter_gene{chr}.csv\"\n",
        "  # out_file9=f\"hfimm_LOV50_{chr}.csv\"\n",
        "\n",
        "  # hfimm_within_gene.to_csv(out_file7)\n",
        "  # hfimm_inter_gene.to_csv(out_file8)\n",
        "  # hfimm_LOV50.to_csv(out_file9)\n",
        "\n",
        "  # shutil.copy(out_file7, outloc)\n",
        "  # shutil.copy(out_file8, outloc)\n",
        "  # shutil.copy(out_file9, outloc)\n",
        "\n",
        "  # # count the variation based on gene type\n",
        "  # hfvar_counts = hfprotvar_wd.drop_duplicates(subset=['Symbol', 'startpos.r', 'endpos.r'])\n",
        "  # gene_count=hfvar_counts.groupby([\"HFgene_type\"]).size().reset_index(name=\"count\")\n",
        "  # out_file10=f\"gene_count{chr}.csv\"\n",
        "  # gene_count.to_csv(out_file10)\n",
        "  # shutil.copy(out_file10, outloc)\n",
        "\n",
        "  # # count substitution per gene\n",
        "  # hf_within_gene_counts=hf_within_gene.drop_duplicates(subset=['Symbol', 'startpos.r', 'endpos.r'])\n",
        "  # counts=hf_within_gene_counts.groupby([\"Symbol\"]).size().reset_index(name=\"count\")\n",
        "  # out_file_10=f\"loc_subs_counts{chr}.csv\"\n",
        "  # counts.to_csv(out_file_10)\n",
        "  # shutil.copy(out_file_10, outloc)\n",
        "  # loc50_subs=counts[counts[\"count\"]>=50]\n",
        "  # out_file1_10=f\"loc50_subs{chr}\"\n",
        "  # shutil.copy(out_file1_10, outloc)\n",
        "\n",
        "  # # # count substitution per immune gene\n",
        "  # hfimm_within_gene_counts=hfimm_within_gene.drop_duplicates(subset=['Symbol', 'startpos.r', 'endpos.r'])\n",
        "  # counts=hfimm_within_gene_counts.groupby([\"Symbol\"]).size().reset_index(name=\"count\")\n",
        "  # out_file_10=f\"immloc_subs_counts{chr}.csv\"\n",
        "  # counts.to_csv(out_file_10)\n",
        "  # shutil.copy(out_file_10, outloc)\n",
        "  # immloc50_subs=counts[counts[\"count\"]>=50]\n",
        "  # out_file1_10=f\"immloc50_subs{chr}\"\n",
        "  # shutil.copy(out_file1_10, outloc)\n",
        "\n",
        "\n",
        "  # # extract the immune has how many variations and its gene type\n",
        "  # hfimmvar_counts = hfimm.drop_duplicates(subset=['Symbol', 'startpos.r', 'endpos.r'])\n",
        "  # imm_count=hfimmvar_counts.groupby(by=[\"Symbol\",\"Name\", \"HFgene_type\"]).size().reset_index(name=\"count\")\n",
        "  # out_file11=f\"immlocus_gene_type_counts{chr}.csv\"\n",
        "  # imm_count.to_csv(out_file11, index=False)\n",
        "  # shutil.copy(out_file11, outloc)\n",
        "\n",
        "  # # Calculate value counts\n",
        "  # count = hfprotvar_wd[\"HFgene_type\"].value_counts().reset_index()\n",
        "  # count.columns = [\"HFgene_type\", \"Count\"]\n",
        "  # count.loc[len(count.index)]=[\"immune_gene\", len(hfimm_within_gene)]\n",
        "  # count.loc[len(count.index)]=[\"non_coding_gene\", len(final_df1)]\n",
        "\n",
        "\n",
        "  # # Save the result to a CSV file\n",
        "  # out_file12=f\"delcount{chr}.csv\"\n",
        "  # count.to_csv(out_file12, index=False)\n",
        "  # shutil.copy(out_file12, outloc)\n",
        "\n",
        "  # #extract idicine genes\n",
        "  # indicineprotvar(hfprotvar_wd, chr, outloc)"
      ],
      "metadata": {
        "id": "lRjg43mLDjdo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def map_keywords(str_sentence):\n",
        "    list_keywords = [\n",
        "        \"immunoglobulin\",\"immunoreceptor\",\"autoimmune\",\"TLR\",\"IgG\",\n",
        "        \"autoimmune\",\"autophagy\",\"immunogen\",\"immune\",\"innate\",\"T-cell\",\"NF-kappa\", \"antigen\",\n",
        "        \"B-cell\",\"lymphocyte\",\"histocompatibility\",\"CD24\",\"CD4\",\"LY96\", \"BCR\",\n",
        "        \"IFIT3\",\"PGLYRP1\",\"NKG2D\",\"UL16\",\"leukocyte\",\"cytokine\", \"interleukin\",\"interferon\"\n",
        "        \"antimicrobial peptide\",\"beta-defensin 2\",\"IL16\",\"IL2\",\"chemokine\", \"antibody\"\n",
        "    ]\n",
        "    bool_found = bool(\n",
        "        [\n",
        "            i for i in list_keywords if i.lower() in str_sentence.lower()\n",
        "        ]\n",
        "    )\n",
        "    return bool_found\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "import shutil\n",
        "\n",
        "# Chr_list=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, \"X\"]\n",
        "Chr_list=[1]\n",
        "for chr in Chr_list:\n",
        "  in_file1=f\"/content/drive/MyDrive/gene_ext/ins/{chr}/common_wd{chr}.csv\"\n",
        "  in_file2=f\"/content/drive/MyDrive/Hereford_VarAnalysis/Hereford_qtl/{chr}/HF_QTL{chr}.csv\"\n",
        "  outloc=f\"/content/drive/MyDrive/Hereford_VarAnalysis/Hereford_chrVar/subs/{chr}\"\n",
        "  common_df=pd.read_csv(in_file1)\n",
        "  hfqtl_df=pd.read_csv(in_file2)\n",
        "\n",
        "  print(\"common_df\", common_df.shape)\n",
        "  print(\"hfqtl_df\", hfqtl_df.shape)\n",
        "\n",
        "\n",
        "  common_df[\"LOV\"]=abs(common_df[\"endpos.q\"]-common_df[\"startpos.q\"])\n",
        "  outf1=f\"common{chr}_LOV.csv\"\n",
        "\n",
        "  common_df.to_csv(outf1)\n",
        "  shutil.copy(outf1, outloc)\n",
        "\n",
        "  hfqtl_df[\"keyword_found\"] = hfqtl_df.apply(lambda row: map_keywords(row[\"Name\"]),axis=1)\n",
        "  outf2=f\"hfqtlprot{chr}.csv\"\n",
        "\n",
        "  hfqtl_df.to_csv(outf2)\n",
        "  shutil.copy(outf2, outloc)\n",
        "\n",
        "  hfqtl_VarAnal(common_df, hfqtl_df, chr, outloc)"
      ],
      "metadata": {
        "id": "_g_rHM_-GFMx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test=pd.read_csv(\"/content/drive/MyDrive/Hereford_VarAnalysis/Hereford_chrVar/ins/1/hfprotvar_wd1.csv\")"
      ],
      "metadata": {
        "id": "MVJ_MB9EAGWg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ijfWI271BYhz",
        "outputId": "c7608b7c-b831-4537-a339-2150b7a526a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "13018"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test2=pd.read_csv(\"/content/drive/MyDrive/Hereford_VarAnalysis/Hereford_chrVar/ins/1/non_coding1.csv\")"
      ],
      "metadata": {
        "id": "R1aPRr5DBebH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(test2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6AxMVMjTBn1K",
        "outputId": "791d3e20-fa17-4169-ffc8-7e4b888a3259"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def hfqtl_VarAnal(common_df, hfqtl_df, chr, outloc):\n",
        "    # Identifying the variations\n",
        "    hfqtl_df.reset_index(drop=True, inplace=True)\n",
        "    common_df.reset_index(drop=True, inplace=True)\n",
        "    final_df = pd.DataFrame(columns=list(hfqtl_df.columns)+[\"HFgene_type\"]+[\"startpos.r\"]+[\"endpos.r\"]+[\"startpos.q\"]+[\"endpos.q\"]+[\"seq.r\"]+[\"seq.q\"]+[\"LOV\"])\n",
        "\n",
        "    for i, row in tqdm(hfqtl_df.iterrows()):\n",
        "        # Check for the at start\n",
        "        start_condition = (row[\"Begin\"] == common_df[\"startpos.r\"]) & (row[\"End\"] > common_df[\"endpos.r\"])\n",
        "        if hfqtl_df[start_condition].shape[0] >= 1:\n",
        "            tmp_df = hfqtl_df[start_condition].copy(deep=True)\n",
        "            tmp_df[\"HFgene_type\"] = \"at_start\"\n",
        "            tmp_df[[\"startpos.r\", \"endpos.r\", \"startpos.q\", \"endpos.q\", \"seq.r\", \"seq.q\", \"LOV\"]] = common_df[[\"startpos.r\", \"endpos.r\", \"startpos.q\", \"endpos.q\", \"seq.r\", \"seq.q\", \"LOV\"]].values\n",
        "            final_df = pd.concat([final_df, tmp_df]).reset_index(drop=True)\n",
        "        start_condition = (row[\"Begin\"] < common_df[\"startpos.r\"]) & (row[\"End\"] == common_df[\"endpos.r\"])\n",
        "        if hfqtl_df[start_condition].shape[0] >= 1:\n",
        "            tmp_df = hfqtl_df[start_condition].copy(deep=True)\n",
        "            tmp_df[\"HFgene_type\"] = \"at_end\"\n",
        "            tmp_df[[\"startpos.r\", \"endpos.r\", \"startpos.q\", \"endpos.q\", \"seq.r\", \"seq.q\", \"LOV\"]] = common_df[[\"startpos.r\", \"endpos.r\", \"startpos.q\", \"endpos.q\", \"seq.r\", \"seq.q\", \"LOV\"]].values\n",
        "            final_df = pd.concat([final_df, tmp_df]).reset_index(drop=True)\n",
        "        start_condition = (hfqtl_df[\"Begin\"] < common_df[\"startpos.r\"]) & (hfqtl_df[\"End\"] > common_df[\"endpos.r\"])\n",
        "        if hfqtl_df[start_condition].shape[0] >= 1:\n",
        "            tmp_df = hfqtl_df[start_condition].copy(deep=True)\n",
        "            tmp_df[\"HFgene_type\"] = \"within\"\n",
        "            tmp_df[[\"startpos.r\", \"endpos.r\", \"startpos.q\", \"endpos.q\", \"seq.r\", \"seq.q\", \"LOV\"]] = common_df[[\"startpos.r\", \"endpos.r\", \"startpos.q\", \"endpos.q\", \"seq.r\", \"seq.q\", \"LOV\"]].values\n",
        "            final_df = pd.concat([final_df, tmp_df]).reset_index(drop=True)\n",
        "        start_condition = (hfqtl_df[\"End\"] < common_df[\"startpos.r\"]) & (hfqtl_df[\"hfstar_of_next_gene\"] > common_df[\"endpos.r\"])\n",
        "        if hfqtl_df[start_condition].shape[0] >= 1:\n",
        "            tmp_df = hfqtl_df[start_condition].copy(deep=True)\n",
        "            tmp_df[\"HFgene_type\"] = \"intergene\"\n",
        "            tmp_df[[\"startpos.r\", \"endpos.r\", \"startpos.q\", \"endpos.q\", \"seq.r\", \"seq.q\", \"LOV\"]] = common_df[[\"startpos.r\", \"endpos.r\", \"startpos.q\", \"endpos.q\", \"seq.r\", \"seq.q\", \"LOV\"]].values\n",
        "            final_df = pd.concat([final_df, tmp_df]).reset_index(drop=True)\n",
        "        # Add other conditions similarly\n",
        "        # ...\n",
        "\n",
        "    # Generate output file\n",
        "    out_file1 = f\"hfprotvar{chr}.csv\"\n",
        "    final_df.to_csv(out_file1, index=False)\n",
        "    print(\"final_df\", len(final_df))\n",
        "\n",
        "    # find variation not present in gene and intergene region called as other non coding region\n",
        "    final_df1 = pd.DataFrame(columns=common_df.columns)\n",
        "    for index, row in tqdm(final_df.iterrows()):\n",
        "        # Check if 'startpos.q' is present in any row of file2\n",
        "        if row['startpos.q'] not in common_df['startpos.q'].values:\n",
        "            # Append the row to the DataFrame if not found\n",
        "            final_df1 = final_df1.append(row, ignore_index=True)\n",
        "\n",
        "    # Save the DataFrame with rows not found in file2 to a new CSV file\n",
        "    out_file2 = f\"non_coding{chr}.csv\"\n",
        "    final_df1.to_csv(out_file2, index=False)\n",
        "    print(\"final_df1\", len(final_df1))"
      ],
      "metadata": {
        "id": "1YHIxErNP-xy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def map_keywords(str_sentence):\n",
        "    list_keywords = [\n",
        "        \"immunoglobulin\",\"immunoreceptor\",\"autoimmune\",\"TLR\",\"IgG\",\n",
        "        \"autoimmune\",\"autophagy\",\"immunogen\",\"immune\",\"innate\",\"T-cell\",\"NF-kappa\", \"antigen\",\n",
        "        \"B-cell\",\"lymphocyte\",\"histocompatibility\",\"CD24\",\"CD4\",\"LY96\", \"BCR\",\n",
        "        \"IFIT3\",\"PGLYRP1\",\"NKG2D\",\"UL16\",\"leukocyte\",\"cytokine\", \"interleukin\",\"interferon\"\n",
        "        \"antimicrobial peptide\",\"beta-defensin 2\",\"IL16\",\"IL2\",\"chemokine\", \"antibody\"\n",
        "    ]\n",
        "    bool_found = bool(\n",
        "        [\n",
        "            i for i in list_keywords if i.lower() in str_sentence.lower()\n",
        "        ]\n",
        "    )\n",
        "    return bool_found\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "import shutil\n",
        "\n",
        "# Chr_list=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, \"X\"]\n",
        "Chr_list=[1]\n",
        "for chr in Chr_list:\n",
        "  in_file1=f\"/content/drive/MyDrive/gene_ext/ins/{chr}/common_wd{chr}.csv\"\n",
        "  in_file2=f\"/content/drive/MyDrive/Hereford_VarAnalysis/Hereford_qtl/{chr}/HF_QTL{chr}.csv\"\n",
        "  outloc=f\"/content/drive/MyDrive/Hereford_VarAnalysis/Hereford_chrVar/subs/{chr}\"\n",
        "  common_df=pd.read_csv(in_file1)\n",
        "  hfqtl_df=pd.read_csv(in_file2)\n",
        "\n",
        "  print(\"common_df\", common_df.shape)\n",
        "  print(\"hfqtl_df\", hfqtl_df.shape)\n",
        "\n",
        "\n",
        "  common_df[\"LOV\"]=abs(common_df[\"endpos.q\"]-common_df[\"startpos.q\"])\n",
        "  outf1=f\"common{chr}_LOV.csv\"\n",
        "\n",
        "  common_df.to_csv(outf1)\n",
        "  shutil.copy(outf1, outloc)\n",
        "\n",
        "  hfqtl_df[\"keyword_found\"] = hfqtl_df.apply(lambda row: map_keywords(row[\"Name\"]),axis=1)\n",
        "  outf2=f\"hfqtlprot{chr}.csv\"\n",
        "\n",
        "  hfqtl_df.to_csv(outf2)\n",
        "  shutil.copy(outf2, outloc)\n",
        "\n",
        "  hfqtl_VarAnal(common_df, hfqtl_df, chr, outloc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "-nBLbz1SR3eh",
        "outputId": "1e117256-a927-4d46-91a7-e68ee61b86dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "common_df (4536, 13)\n",
            "hfqtl_df (3435, 19)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "0it [00:00, ?it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-598dc842697b>\u001b[0m in \u001b[0;36m<cell line: 25>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     46\u001b[0m   \u001b[0mshutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutf2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutloc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m   \u001b[0mhfqtl_VarAnal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommon_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhfqtl_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutloc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-17-4dcd8af6d08b>\u001b[0m in \u001b[0;36mhfqtl_VarAnal\u001b[0;34m(common_df, hfqtl_df, chr, outloc)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhfqtl_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterrows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0;31m# Check for the at start\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mstart_condition\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhfqtl_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Begin\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mcommon_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"startpos.r\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhfqtl_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"End\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mcommon_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"endpos.r\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhfqtl_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart_condition\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m             \u001b[0mtmp_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhfqtl_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart_condition\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdeep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/ops/common.py\u001b[0m in \u001b[0;36mnew_method\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0mother\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mitem_from_zerodim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnew_method\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/arraylike.py\u001b[0m in \u001b[0;36m__eq__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0munpack_zerodim_and_defer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"__eq__\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__eq__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cmp_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moperator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0munpack_zerodim_and_defer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"__ne__\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m_cmp_method\u001b[0;34m(self, other, op)\u001b[0m\n\u001b[1;32m   6235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6236\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSeries\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_indexed_same\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6237\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Can only compare identically-labeled Series objects\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6238\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6239\u001b[0m         \u001b[0mlvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Can only compare identically-labeled Series objects"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}